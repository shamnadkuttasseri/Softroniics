{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cff9284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d9b6c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample text data\n",
    "texts=['This is the first document',\n",
    "      'This  document is the second document',\n",
    "      'And this id the third one',\n",
    "       'Is this the first document']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245ff35f",
   "metadata": {},
   "source": [
    "Tokenize the text:Split your text into individual words or tokens.\n",
    "\n",
    "create a vocabulary build a vocabulary mapping each unique word/token to an integer index.\n",
    "\n",
    "convert text to sequences: replace each word/token in the text with its corresponding integer index based on the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2c95006",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(texts)\n",
    "word_index=tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b84667af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 1,\n",
       " 'the': 2,\n",
       " 'document': 3,\n",
       " 'is': 4,\n",
       " 'first': 5,\n",
       " 'second': 6,\n",
       " 'and': 7,\n",
       " 'id': 8,\n",
       " 'third': 9,\n",
       " 'one': 10}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac2e4fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdd95518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 4, 2, 5, 3], [1, 3, 4, 2, 6, 3], [7, 1, 8, 2, 9, 10], [4, 1, 2, 5, 3]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da83fef",
   "metadata": {},
   "source": [
    "tokenize the text using Tokenizer and convert it into sequences of integers,pad the sequences to ensure they all have the same length.\n",
    "\n",
    "then create an embedidng matrix using Embedding layer,where each word index in the  sequences is mapped to a dense vector representation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "336751b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step3:pad sequences{optional}\n",
    "#Ensure all sequences have the same length by padding then with zeros or truncating then,\n",
    "max_sequence_length=max([len(seq)for seq in sequences])\n",
    "sequences_padded=pad_sequences(sequences,max_sequence_length,padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52bceb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  4,  2,  5,  3,  0],\n",
       "       [ 1,  3,  4,  2,  6,  3],\n",
       "       [ 7,  1,  8,  2,  9, 10],\n",
       "       [ 4,  1,  2,  5,  3,  0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecad5139",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 4: Apply Embedded layer\n",
    "vocab_size=len(word_index)+1#Add 1 for the padding token\n",
    "embedding_dim=10 #Dimensionality of the dense embedding,how many features we want to get\n",
    "embedding_matrix=tf.keras.layers.Embedding(vocab_size,embedding_dim)(sequences_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c138c38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55dfeb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 6, 10), dtype=float32, numpy=\n",
       "array([[[ 0.00701129,  0.02009818,  0.00326275,  0.01492188,\n",
       "          0.03935621, -0.00760423, -0.00146579,  0.03328215,\n",
       "          0.03673149,  0.03602679],\n",
       "        [ 0.04040361, -0.01636294,  0.0281814 ,  0.02929983,\n",
       "         -0.0008631 , -0.02536528,  0.03114644,  0.02887237,\n",
       "          0.01377065, -0.04836928],\n",
       "        [-0.03494245, -0.00624971,  0.0339229 ,  0.02501868,\n",
       "         -0.03530798, -0.02711538, -0.00470088, -0.03875319,\n",
       "          0.02784597,  0.03366885],\n",
       "        [ 0.04779335,  0.04108945,  0.01618012, -0.0264813 ,\n",
       "          0.00070152,  0.03477964,  0.00808493, -0.00257443,\n",
       "         -0.03787651, -0.04506816],\n",
       "        [ 0.02148118,  0.00810901,  0.01190414,  0.02135411,\n",
       "         -0.0082275 , -0.00447562, -0.01178296,  0.01784093,\n",
       "         -0.02615254, -0.02689477],\n",
       "        [-0.01592624,  0.01468157, -0.01513099, -0.02661245,\n",
       "          0.03715931, -0.01974171,  0.04762168,  0.00067891,\n",
       "          0.02022967, -0.03037271]],\n",
       "\n",
       "       [[ 0.00701129,  0.02009818,  0.00326275,  0.01492188,\n",
       "          0.03935621, -0.00760423, -0.00146579,  0.03328215,\n",
       "          0.03673149,  0.03602679],\n",
       "        [ 0.02148118,  0.00810901,  0.01190414,  0.02135411,\n",
       "         -0.0082275 , -0.00447562, -0.01178296,  0.01784093,\n",
       "         -0.02615254, -0.02689477],\n",
       "        [ 0.04040361, -0.01636294,  0.0281814 ,  0.02929983,\n",
       "         -0.0008631 , -0.02536528,  0.03114644,  0.02887237,\n",
       "          0.01377065, -0.04836928],\n",
       "        [-0.03494245, -0.00624971,  0.0339229 ,  0.02501868,\n",
       "         -0.03530798, -0.02711538, -0.00470088, -0.03875319,\n",
       "          0.02784597,  0.03366885],\n",
       "        [ 0.02530307, -0.04963247, -0.00621996,  0.02084312,\n",
       "          0.00261091,  0.03926842, -0.04576776,  0.01751447,\n",
       "         -0.0469816 , -0.0070367 ],\n",
       "        [ 0.02148118,  0.00810901,  0.01190414,  0.02135411,\n",
       "         -0.0082275 , -0.00447562, -0.01178296,  0.01784093,\n",
       "         -0.02615254, -0.02689477]],\n",
       "\n",
       "       [[ 0.0159878 ,  0.00245734,  0.00461655,  0.03386039,\n",
       "          0.04995329,  0.03013552,  0.01648135,  0.00532116,\n",
       "         -0.03956313,  0.01442689],\n",
       "        [ 0.00701129,  0.02009818,  0.00326275,  0.01492188,\n",
       "          0.03935621, -0.00760423, -0.00146579,  0.03328215,\n",
       "          0.03673149,  0.03602679],\n",
       "        [-0.02049792, -0.00511779,  0.01436714,  0.03949511,\n",
       "          0.03962343, -0.01887864, -0.04432926,  0.00536259,\n",
       "         -0.01350309,  0.01221506],\n",
       "        [-0.03494245, -0.00624971,  0.0339229 ,  0.02501868,\n",
       "         -0.03530798, -0.02711538, -0.00470088, -0.03875319,\n",
       "          0.02784597,  0.03366885],\n",
       "        [ 0.04914166, -0.04239185, -0.04229233, -0.01244049,\n",
       "          0.00759908, -0.01312897, -0.04777179,  0.00174564,\n",
       "          0.03798118,  0.02652887],\n",
       "        [ 0.01048937,  0.03737731, -0.0407909 , -0.04351632,\n",
       "          0.02897706, -0.02427178, -0.03280433, -0.0118178 ,\n",
       "         -0.02600629,  0.02234744]],\n",
       "\n",
       "       [[ 0.04040361, -0.01636294,  0.0281814 ,  0.02929983,\n",
       "         -0.0008631 , -0.02536528,  0.03114644,  0.02887237,\n",
       "          0.01377065, -0.04836928],\n",
       "        [ 0.00701129,  0.02009818,  0.00326275,  0.01492188,\n",
       "          0.03935621, -0.00760423, -0.00146579,  0.03328215,\n",
       "          0.03673149,  0.03602679],\n",
       "        [-0.03494245, -0.00624971,  0.0339229 ,  0.02501868,\n",
       "         -0.03530798, -0.02711538, -0.00470088, -0.03875319,\n",
       "          0.02784597,  0.03366885],\n",
       "        [ 0.04779335,  0.04108945,  0.01618012, -0.0264813 ,\n",
       "          0.00070152,  0.03477964,  0.00808493, -0.00257443,\n",
       "         -0.03787651, -0.04506816],\n",
       "        [ 0.02148118,  0.00810901,  0.01190414,  0.02135411,\n",
       "         -0.0082275 , -0.00447562, -0.01178296,  0.01784093,\n",
       "         -0.02615254, -0.02689477],\n",
       "        [-0.01592624,  0.01468157, -0.01513099, -0.02661245,\n",
       "          0.03715931, -0.01974171,  0.04762168,  0.00067891,\n",
       "          0.02022967, -0.03037271]]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47de5504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 10)\n"
     ]
    }
   ],
   "source": [
    "#print the embedding matrix shape\n",
    "print(embedding_matrix.shape)  #Output:(num_samples,max_sequence_length,embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f386c7",
   "metadata": {},
   "source": [
    "Dimension 1(4): This dimension corresponds to the number of samples in your input data\n",
    "\n",
    "Dimension 2(6):represent the length of the sequences after padding\n",
    "\n",
    "Dimension 3(10):dimensionality of the dense embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfb06c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
